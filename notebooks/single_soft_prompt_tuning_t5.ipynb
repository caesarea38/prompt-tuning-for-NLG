{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIoYkDMph0qI"
   },
   "source": [
    "## Installing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uemA2s_7h0qO",
    "outputId": "efb9349d-2532-499d-ecef-8e77304b4774"
   },
   "outputs": [],
   "source": [
    "!pip install transformers --quiet\n",
    "!pip install sentencepiece --quiet\n",
    "!pip install -Uqq ipdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtPNBfoDh0qQ"
   },
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2gK6uqcrh0qQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 14:56:08.567807: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-13 14:56:08.567877: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipdb\n",
    "\n",
    "from itertools import chain\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, get_scheduler\n",
    "from transformers.optimization import Adafactor, AdamW\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9e6cPibh0qR",
    "outputId": "6cbed112-4319-424a-8096-ff5deda42218"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Use this when working on Google Colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNixl_L6qRAJ"
   },
   "source": [
    "## Define the Class for Prompt Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YU0rg9NRxbkm"
   },
   "outputs": [],
   "source": [
    "class T5PromptTuning(T5ForConditionalGeneration):\n",
    "    def __init__(self, config):\n",
    "          super().__init__(config)\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_name_or_path: str, soft_prompt_path: str = None, number_tokens: int = None,\n",
    "        initialize_from_vocab: bool = True, random_range: float = 0.5, **kwargs):\n",
    "      \n",
    "        model = super().from_pretrained(model_name_or_path, **kwargs)\n",
    "  \n",
    "        #  freeze the transformers model\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # if a saved soft prompt is loaded, use its embeddings\n",
    "        if soft_prompt_path is not None: \n",
    "          model.set_soft_prompt_embeds(soft_prompt_path=soft_prompt_path)\n",
    "        # else create a new soft prompt\n",
    "        elif number_tokens is not None:\n",
    "            print(\"Initializing soft prompt\")\n",
    "            model.initialize_soft_prompt(number_tokens=number_tokens, initialize_from_vocab=initialize_from_vocab, random_range=random_range)\n",
    "        return model\n",
    "\n",
    "    def set_soft_prompt_embeds(self, soft_prompt_path):\n",
    "        self.soft_prompt = torch.load(\n",
    "            soft_prompt_path, map_location=torch.device(\"cpu\")\n",
    "        )\n",
    "        self.number_tokens = self.soft_prompt.shape[0]\n",
    "        print(f\"Set soft prompt. (number_tokens: {self.number_tokens})\")\n",
    "\n",
    "    def initialize_soft_prompt(self, number_tokens: int = 20, initialize_from_vocab: bool = True, random_range: float = 0.5):\n",
    "        self.number_tokens = number_tokens\n",
    "        if initialize_from_vocab:\n",
    "            init_prompt_value = self.shared.weight[:number_tokens].clone().detach()\n",
    "        else:\n",
    "            init_prompt_value = torch.FloatTensor(number_tokens, self.config.d_model).uniform_(-random_range, random_range)\n",
    "\n",
    "        print(init_prompt_value.shape)\n",
    "        print(self.shared.weight.shape)\n",
    "\n",
    "        # Initialize weight\n",
    "        self.soft_prompt = torch.nn.parameter.Parameter(init_prompt_value)\n",
    "\n",
    "    def get_soft_params(self):\n",
    "        return self.soft_prompt\n",
    "\n",
    "    # this method appends the learned prompt embeddings to the input ids of the input before the forward pass is calculated\n",
    "    def append_learned_embedding_to_input(self, input_ids):\n",
    "        inputs_embeds = self.shared(input_ids)\n",
    "        \n",
    "        if len(list(inputs_embeds.shape)) == 2: inputs_embeds = inputs_embeds.unsqueeze(0)\n",
    "\n",
    "        # the shape of the tensor that will be returned will be: [batch_size, max_sequence_length, number_embeddings] -> [8, 600, 512]\n",
    "        learned_embeds = self.soft_prompt.repeat(inputs_embeds.size(0), 1, 1)\n",
    "        return torch.cat([learned_embeds, inputs_embeds], dim=1)\n",
    "\n",
    "    # to make sure that padding token ids of the labels are not taken into account by the loss function\n",
    "    # this method extends the labels tensor by elements that are ignored by the CrossEntropyLoss function\n",
    "    # this can be done using the ignore_index value -100\n",
    "    def extend_labels(self, labels, ignore_index=-100):\n",
    "        if len(list(labels.shape)) == 1: labels = labels.unsqueeze(0)\n",
    "        number_of_batches = labels.shape[0]\n",
    "\n",
    "        # return a new tensor of shape [number_of_batches, number_tokens+labels] that is filled with the ignore_index value (-100)\n",
    "        return torch.cat([torch.full((number_of_batches, self.number_tokens), ignore_index).to(self.device), labels], dim=1)\n",
    "\n",
    "    def extend_attention_mask(self, attention_mask):\n",
    "        # prepend a new dimension (1) to the shape of attention_mask in case it is one dimensional\n",
    "        if len(list(attention_mask.shape)) == 1: attention_mask = attention_mask.unsqueeze(0)\n",
    "\n",
    "        # get the number of batches\n",
    "        number_of_batches = attention_mask.shape[0]\n",
    "\n",
    "        # return a new tensor of shape [number_of_batches, number_tokens+attention_mask] that is filled with the ones\n",
    "        return torch.cat([torch.full((number_of_batches, self.number_tokens), 1).to(self.device), attention_mask], dim=1)\n",
    "\n",
    "    def save_soft_prompt(self, challenge_name, epochs, model_size, number_tokens):\n",
    "        torch.save(self.soft_prompt, f'soft_prompts/soft_prompt_{challenge_name}_t5_{model_size}_{epochs}_epochs_{number_tokens}_tokens.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxsDKQlsh0qR"
   },
   "source": [
    "## Load the Pre-trained model T5 and the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KyZrfrkoh0qS",
    "outputId": "9e178989-89d6-4f00-c374-86eae86b9648"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the CPU\n",
      "Initializing soft prompt\n",
      "torch.Size([50, 512])\n",
      "torch.Size([32128, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5PromptTuning(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as nn\n",
    "# Check GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    dev = torch.device(\"cuda:0\")\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    dev = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")\n",
    "\n",
    "# Comment out below lines to print Cuda device properties\n",
    "\n",
    "#print(torch.cuda.get_device_properties(0))\n",
    "#print(torch.cuda.get_device_name(0))\n",
    "#torch.cuda.empty_cache()\n",
    "#torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "\n",
    "# Single Soft Prompt-tuning: You can specify the number of prompt tokens that should be used for training and whether the soft prompt\n",
    "# should be loaded from the vocabulary (default) or should be randomly initialized (set random_range)\n",
    "\n",
    "# number of prompt tokens\n",
    "number_prompt_tokens = 50\n",
    "\n",
    "# If set to true, the soft prompt will be initialized from the models vocabulary\n",
    "# Otherwise, it will be randomly (uniformly in a range) initialized.\n",
    "random_range = 0.5\n",
    "init_from_vocab = True\n",
    "\n",
    "try:\n",
    "  del inputs_train_amr\n",
    "  del inputs_test_amr\n",
    "  del model_t5_small\n",
    "  gc.collect()\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# IMPORTANT: set the following variable to either 'small' or 'base' to train on T5 small or base\n",
    "model_size = 'small'\n",
    "\n",
    "# Instantiate one T5  model that can be trained on all the 3 datasets\n",
    "\n",
    "# LOAD a saved soft prompt and a new T5 model (change the path to specify another saved soft prompt)\n",
    "#model_t5 = T5PromptTuning.from_pretrained('ft5-{model_size}', soft_prompt_path='soft_prompts/soft_prompt_e2e_t5_small_20_epochs_50_tokens.model')\n",
    "\n",
    "# CREATE a new mode soft prompt and a new T5 model\n",
    "model_t5 = T5PromptTuning.from_pretrained(f't5-{model_size}', number_tokens=number_prompt_tokens, initialize_from_vocab=init_from_vocab)\n",
    "\n",
    "# Set the tokenizer\n",
    "tokenizer_t5 = T5Tokenizer.from_pretrained(f't5-{model_size}')\n",
    "\n",
    "#moving the models to device(GPU/CPU)\n",
    "model_t5.to(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YA92MUkIh0qU"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qRBcOeOFh0qU"
   },
   "outputs": [],
   "source": [
    "load_no_duplicate_sets = True\n",
    "\n",
    "# If you work on google colab upload the challenge datasets to your drive and change the paths below\n",
    "# to load the datasets from drive\n",
    "\n",
    "# Load the datasets for the Web NLG 2020 challenge\n",
    "#train_data_web_nlg = pd.read_csv('drive/MyDrive/MIwDL/data/web_nlg/train/webNLG2020_train.csv' if not load_no_duplicate_sets else 'drive/MyDrive/MIwDL/data/web_nlg/train/webNLG2020_train_no_duplicate_inputs.csv')\n",
    "#test_data_web_nlg = pd.read_csv('drive/MyDrive/MIwDL/data/web_nlg/test/webNLG2020_test.csv' if not load_no_duplicate_sets else 'drive/MyDrive/MIwDL/data/web_nlg/test/webNLG2020_test_no_duplicate_inputs.csv')\n",
    "\n",
    "# Load the datasets for the Meaning Representation E2E challenge\n",
    "#train_data_e2e = pd.read_csv('drive/MyDrive/MIwDL/data/e2e/train/trainset.csv' if not load_no_duplicate_sets else 'drive/MyDrive/MIwDL/data/e2e/train/trainset_no_duplicate_inputs.csv')\n",
    "#test_data_e2e = pd.read_csv('drive/MyDrive/MIwDL/data/e2e/test/testset_w_refs.csv' if not load_no_duplicate_sets else 'drive/MyDrive/MIwDL/data/e2e/test/testset_no_duplicate_inputs.csv')\n",
    "\n",
    "# Load the datasets for the Abstract Meaning Representation AMR challenge\n",
    "#train_data_amr = pd.read_csv('drive/MyDrive/MIwDL/data/amr/abstract_meaning_representation_train.csv' if not load_no_duplicate_sets else 'drive/MyDrive/MIwDL/data/amr/train/amr_train_no_duplicate_inputs.csv')\n",
    "#test_data_amr = pd.read_csv('drive/MyDrive/MIwDL/data/amr/abstract_meaning_representation_test.csv' if not load_no_duplicate_sets else 'drive/MyDrive/MIwDL/data/amr/test/amr_test_no_duplicate_inputs.csv')\n",
    "\n",
    "# Load the datasets for the Web NLG 2020 challenge\n",
    "train_data_web_nlg = pd.read_csv('data/web_nlg/train/webNLG2020_train.csv' if not load_no_duplicate_sets else 'data/web_nlg/train/webNLG2020_train_no_duplicate_inputs.csv')\n",
    "test_data_web_nlg = pd.read_csv('data/web_nlg/test/webNLG2020_test.csv' if not load_no_duplicate_sets else 'data/web_nlg/test/webNLG2020_test_no_duplicate_inputs.csv')\n",
    "\n",
    "# Load the datasets for the Meaning Representation E2E challenge\n",
    "train_data_e2e = pd.read_csv('data/e2e/train/trainset.csv' if not load_no_duplicate_sets else 'data/e2e/train/trainset_no_duplicate_inputs.csv' )\n",
    "test_data_e2e = pd.read_csv('data/e2e/test/testset_w_refs.csv' if not load_no_duplicate_sets else 'data/e2e/test/testset_no_duplicate_inputs.csv')\n",
    "\n",
    "# Load the datasets for the Abstract Meaning Representation AMR challenge\n",
    "train_data_amr = pd.read_csv('data/amr/train/abstract_meaning_representation_train.csv' if not load_no_duplicate_sets else 'data/amr/train/amr_train_no_duplicate_inputs.csv')\n",
    "test_data_amr = pd.read_csv('data/amr/test/abstract_meaning_representation_test.csv' if not load_no_duplicate_sets else 'data/amr/test/amr_test_no_duplicate_inputs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FrFGcPdzY6X2"
   },
   "outputs": [],
   "source": [
    "# sort the values by ascending order\n",
    "test_data_web_nlg = test_data_web_nlg.sort_values(by='input_text', ignore_index=True)\n",
    "train_data_web_nlg = train_data_web_nlg.sort_values(by='input_text', ignore_index=True)\n",
    "\n",
    "test_data_e2e = test_data_e2e.sort_values(by='input_text', ignore_index=True)\n",
    "train_data_e2e = train_data_e2e.sort_values(by='input_text', ignore_index=True)\n",
    "\n",
    "train_data_amr = train_data_amr.sort_values(by='input_text', ignore_index=True)\n",
    "test_data_amr = test_data_amr.sort_values(by='input_text', ignore_index=True)\n",
    "\n",
    "# Trimming off the last few datapoints from Web NLG so hat a batch would not leave any remainder.\n",
    "train_data_web_nlg = train_data_web_nlg.iloc[:35200,:] if not load_no_duplicate_sets else train_data_web_nlg.iloc[:len(train_data_web_nlg)-3,:]\n",
    "test_data_web_nlg = test_data_web_nlg.iloc[:1720,:] if not load_no_duplicate_sets else test_data_web_nlg.iloc[:len(test_data_web_nlg)-7,:]\n",
    "\n",
    "# Trimming off the last few datapoints from E2E so that a batch would not leave any remainder.\n",
    "train_data_e2e = train_data_e2e.iloc[:len(train_data_e2e)-1,:] if not load_no_duplicate_sets else train_data_e2e.iloc[:len(train_data_e2e)-6,:]\n",
    "test_data_e2e = test_data_e2e.iloc[:len(test_data_e2e)-5,:] if not load_no_duplicate_sets else test_data_e2e.iloc[:len(test_data_e2e)-6,:]\n",
    "\n",
    "# Trimming off the last few datapoints from AMR so that a batch would not leave any remainder.\n",
    "train_data_amr = train_data_amr.iloc[:len(train_data_amr)-4,:] if not load_no_duplicate_sets else train_data_amr.iloc[:len(train_data_amr)-6,:]\n",
    "test_data_amr = test_data_amr.iloc[:len(test_data_amr)-6,:] if not load_no_duplicate_sets else test_data_amr.iloc[:len(test_data_amr)-3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RMhX5cjnh0qW",
    "outputId": "b0917186-db04-4dbe-a569-92bac2d2f288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Number of train batches Web NLG: 1640 --- \n",
      "--- Number of test  batches Web NLG: 74  --- \n",
      "\n",
      "--- Number of train batches E2E : 607 --- \n",
      "--- Number of test  batches E2E : 78  --- \n",
      "\n",
      "--- Number of train batches AMR : 168 --- \n",
      "--- Number of test  batches AMR : 18  --- \n"
     ]
    }
   ],
   "source": [
    "# Set the batch sizes\n",
    "batch_size_web_nlg = 8\n",
    "batch_size_e2e = 8\n",
    "batch_size_amr = 8\n",
    "\n",
    "number_of_batches_train_web_nlg = int(len(train_data_web_nlg)/batch_size_web_nlg)\n",
    "number_of_batches_test_web_nlg = int(len(test_data_web_nlg)/batch_size_web_nlg)\n",
    "\n",
    "number_of_batches_train_e2e = int(len(train_data_e2e)/batch_size_e2e)\n",
    "number_of_batches_test_e2e = int(len(test_data_e2e)/batch_size_e2e)\n",
    "\n",
    "number_of_batches_train_amr = int(len(train_data_amr)/batch_size_amr)\n",
    "number_of_batches_test_amr = int(len(test_data_amr)/batch_size_amr)\n",
    "\n",
    "print('--- Number of train batches Web NLG: ' + str(number_of_batches_train_web_nlg) + ' --- ')\n",
    "print('--- Number of test  batches Web NLG: ' + str(number_of_batches_test_web_nlg) + '  --- \\n')\n",
    "\n",
    "print('--- Number of train batches E2E : ' + str(number_of_batches_train_e2e) + ' --- ')\n",
    "print('--- Number of test  batches E2E : ' + str(number_of_batches_test_e2e) + '  --- \\n')\n",
    "\n",
    "print('--- Number of train batches AMR : ' + str(number_of_batches_train_amr) + ' --- ')\n",
    "print('--- Number of test  batches AMR : ' + str(number_of_batches_test_amr) + '  --- ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sxy2hYEYh0qX"
   },
   "outputs": [],
   "source": [
    "def create_list_of_batches(batch_size, num_batches, data, tokenizer):\n",
    "# Create List of batches for inputs and labels\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    for i in range(num_batches):\n",
    "        input_batch=[]\n",
    "        label_batch=[]\n",
    "        for index,row in data[i*batch_size:i*batch_size+batch_size].iterrows():\n",
    "#          input_batch.append('translate from Graph to Text: '+row['input_text']+'</s>')\n",
    "#          label_batch.append(row['target_text']+'</s>')\n",
    "\n",
    "          input_batch.append('translate from Graph to Text: '+row['input_text'])\n",
    "          label_batch.append(row['target_text'])\n",
    "\n",
    "        input_batch=tokenizer.batch_encode_plus(input_batch,padding=True, return_tensors='pt', return_attention_mask=True)\n",
    "        label_batch=tokenizer.batch_encode_plus(label_batch,padding=True, return_tensors='pt', return_attention_mask=True)\n",
    "\n",
    "        input_batch=input_batch.to(dev)\n",
    "        label_batch=label_batch.to(dev)\n",
    "\n",
    "        inputs.append(input_batch)\n",
    "        labels.append(label_batch)\n",
    "    return inputs, labels\n",
    "\n",
    "inputs_train_web_nlg, \\\n",
    "labels_train_web_nlg = create_list_of_batches(batch_size=batch_size_web_nlg,\n",
    "                                              num_batches=number_of_batches_train_web_nlg,\n",
    "                                              data=train_data_web_nlg,\n",
    "                                              tokenizer=tokenizer_t5)\n",
    "inputs_test_web_nlg, \\\n",
    "labels_test_web_nlg = create_list_of_batches(batch_size=batch_size_web_nlg,\n",
    "                                              num_batches=number_of_batches_test_web_nlg,\n",
    "                                              data=test_data_web_nlg,\n",
    "                                              tokenizer=tokenizer_t5)\n",
    "inputs_train_e2e, \\\n",
    "labels_train_e2e = create_list_of_batches(batch_size=batch_size_e2e,\n",
    "                                              num_batches=number_of_batches_train_e2e,\n",
    "                                              data=train_data_e2e,\n",
    "                                              tokenizer=tokenizer_t5)\n",
    "inputs_test_e2e, \\\n",
    "labels_test_e2e = create_list_of_batches(batch_size=batch_size_e2e,\n",
    "                                              num_batches=number_of_batches_test_e2e,\n",
    "                                              data=test_data_e2e,\n",
    "                                              tokenizer=tokenizer_t5)\n",
    "inputs_train_amr, \\\n",
    "labels_train_amr = create_list_of_batches(batch_size=batch_size_amr,\n",
    "                                              num_batches=number_of_batches_train_amr,\n",
    "                                              data=train_data_amr,\n",
    "                                              tokenizer=tokenizer_t5)\n",
    "inputs_test_amr, \\\n",
    "labels_test_amr = create_list_of_batches(batch_size=batch_size_amr,\n",
    "                                              num_batches=number_of_batches_test_amr,\n",
    "                                              data=test_data_amr,\n",
    "                                              tokenizer=tokenizer_t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4u8a5oqh0qY"
   },
   "source": [
    "\n",
    "## Set the Optimizer for T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VKXdRP2yh0qY"
   },
   "outputs": [],
   "source": [
    "def optimizer_adafactor(model, \n",
    "              lr=0.3,\n",
    "              eps=(1e-30, 1e-3),\n",
    "              clip_threshold=1.0,\n",
    "              decay_rate=-0.8,\n",
    "              beta1=None,\n",
    "              weight_decay=1e-5,\n",
    "              relative_step=False,   \n",
    "              scale_parameter=False,\n",
    "              warmup_init=False):\n",
    "  \n",
    "    return Adafactor(\n",
    "        [model.get_soft_params()],\n",
    "        lr=lr,\n",
    "        eps=eps,\n",
    "        clip_threshold=clip_threshold,\n",
    "        decay_rate=decay_rate,\n",
    "        beta1=beta1,\n",
    "        weight_decay=weight_decay,\n",
    "        relative_step=relative_step,\n",
    "        scale_parameter=scale_parameter,\n",
    "        warmup_init=warmup_init\n",
    "    )\n",
    "optimizer_t5 = optimizer_adafactor(model_t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNBoD0Mth0qZ"
   },
   "source": [
    "## Training Routine Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "osZOfoXAh0qZ"
   },
   "outputs": [],
   "source": [
    "def progress(loss,value, max=100):\n",
    "    return HTML(\"\"\" Batch loss :{loss}\n",
    "        <progress\n",
    "            value='{value}'\n",
    "            max='{max}',\n",
    "            style='width: 100%'\n",
    "        >\n",
    "            {value}\n",
    "        </progress>\n",
    "    \"\"\".format(loss=loss,value=value, max=max))\n",
    "\n",
    "def trainer(model, num_batches, inputs, labels, optimizer, challenge_name, model_name):\n",
    "    # Set the model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    loss_per_10_steps=[]\n",
    "    for epoch in range(1,epochs+1):\n",
    "      print('Running epoch: {}'.format(epoch))\n",
    "      running_loss=0\n",
    "\n",
    "      out = display(progress(1, num_batches+1), display_id=True)\n",
    "      for i in range(num_batches):\n",
    "\n",
    "        # clear out the gradients of all Variables\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward propogation\n",
    "        #outputs = model(input_ids=inputs[i]['input_ids'], labels=labels[i]['input_ids'], attention_mask=inputs[i]['attention_mask'])\n",
    "        outputs = model(inputs_embeds=model.append_learned_embedding_to_input(inputs[i]['input_ids']), labels=model.extend_labels(labels[i]['input_ids']), attention_mask= model.extend_attention_mask(inputs[i]['attention_mask']))\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        loss_num=loss.item()\n",
    "        logits = outputs.logits\n",
    "        running_loss+=loss_num\n",
    "        if i%10 == 0: loss_per_10_steps.append(loss_num)\n",
    "        out.update(progress(loss_num,i, num_batches+1))\n",
    "\n",
    "        # calculating the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #updating the params\n",
    "        optimizer.step()\n",
    "\n",
    "      running_loss=running_loss/int(num_batches)\n",
    "      print('Epoch: {} , Running loss: {}'.format(epoch,running_loss))\n",
    "\n",
    "      # plot the loss\n",
    "      steps = [i for i in range(len(loss_per_10_steps))]\n",
    "      plt.plot(steps, loss_per_10_steps)\n",
    "      plt.title(f'Loss curve for the {challenge_name} challenge trained for {epochs} epochs on T5-{model_name}')\n",
    "      plt.xlabel('Steps')\n",
    "      plt.ylabel('Loss')\n",
    "      plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQG9jyovcPZc"
   },
   "source": [
    "## Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BdU_O7VN6op5"
   },
   "outputs": [],
   "source": [
    "# Set the number of epochs to train\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DZDXEP8bW21T",
    "outputId": "6d23ddfe-5bfe-43ec-f671-c583368a295d"
   },
   "outputs": [],
   "source": [
    "# Since this is Single soft prompt tuning, chose one of the following three cells only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " Batch loss :5.943585395812988\n",
       "        <progress\n",
       "            value='5'\n",
       "            max='169',\n",
       "            style='width: 100%'\n",
       "        >\n",
       "            5\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train T5 on AMR\n",
    "model_t5 = trainer(model=model_t5, num_batches=number_of_batches_train_amr, inputs=inputs_train_amr, labels=labels_train_amr,optimizer=optimizer_t5,challenge_name='AMR', model_name=f'{model_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train T5 on E2E\n",
    "model_t5 = trainer(model=model_t5, num_batches=number_of_batches_train_e2e, inputs=inputs_train_e2e, labels=labels_train_e2e,optimizer=optimizer_t5,challenge_name='E2E', model_name=f'{model_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train T5 on Web NLG\n",
    "model_t5 = trainer(model=model_t5, num_batches=number_of_batches_train_web_nlg, inputs=inputs_train_web_nlg, labels=labels_train_web_nlg,optimizer=optimizer_t5,challenge_name='Web NLG', model_name=f'{model_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lcpAnNzxIKC"
   },
   "source": [
    "## Evaluate a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vHYrhlgB_ZDe"
   },
   "outputs": [],
   "source": [
    "# use this method to generate text for each test input ids, then save the predictions\n",
    "# in a file 'hypothesis' for web nlg and amr to later use the official evaluation script for the \n",
    "# challenges\n",
    "def make_predictions(model, inputs_test, tokenizer, challenge_name):\n",
    "\n",
    "  model_predictions = []\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for i in range(len(inputs_test)):\n",
    "      embeds = model.append_learned_embedding_to_input(inputs_test[i]['input_ids'])\n",
    "      output = tokenizer.batch_decode(model.generate(inputs_embeds=embeds,\n",
    "                                                     #do_sample=True, \n",
    "                                                     max_length=400,\n",
    "                                                     #top_p=0.92,\n",
    "                                                     #top_k=0,\n",
    "                                                     bos_token_id=0,\n",
    "                                                     pad_token_id=0,\n",
    "                                                     eos_token_id=1,\n",
    "                                                     use_cache=True,\n",
    "                                                     attention_mask=model.extend_attention_mask(inputs_test[i]['attention_mask'])\n",
    "                                                     ),\n",
    "                                      skip_special_tokens=True,\n",
    "                                      )\n",
    "      print(output)\n",
    "      model_predictions.append([x.replace('<pad>','').replace('</s>','').strip() for x in output])\n",
    "\n",
    "    # flatten the predictions list which has the length of batch_size * number_of_batches\n",
    "    model_predictions = list(chain(*model_predictions))  \n",
    "  model.train()\n",
    "\n",
    "  # if you are working on colab set the path to which you want to save the output file\n",
    "  #with open('drive/MyDrive/MIwDL/data/' + challenge_name + '/test/prompt_tuning_hypothesis/hypothesis', 'w') as file:\n",
    "  #  for i in range(len(model_predictions)):\n",
    "  #    file.write(model_predictions[i] + '\\n' if i < len(model_predictions)-1 else model_predictions[i])\n",
    "\n",
    "  with open(f'data/{challenge_name}/test/prompt_tuning_hypothesis/hypothesis', 'w') as file:\n",
    "    for i in range(len(model_predictions)):\n",
    "      file.write(model_predictions[i] + '\\n' if i < len(model_predictions)-1 else model_predictions[i])\n",
    "\n",
    "  return model_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UkCgGtDRsP0P",
    "outputId": "030b7c24-5736-4ef6-efab-8c938f0f8d30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Blue Spice is a coffee shop in the city centre.', 'Blue Spice is a coffee shop located in the riverside area.', 'Blue Spice is a coffee shop near Crowne Plaza Hotel.', 'Blue Spice is a coffee shop near Burger King.', 'Blue Spice is a coffee shop near Crowne Plaza Hotel.', 'Blue Spice is located in the city centre.', 'Blue Spice is a pub located in the riverside.', 'Blue Spice is a pub near Crowne Plaza Hotel.']\n",
      "['Blue Spice is a pub near Burger King.', 'Blue Spice is a pub near Crowne Plaza Hotel.', 'Blue Spice is located in the city centre.', 'Blue Spice is located in the city centre.', 'Blue Spice is a Chinese pub in the riverside area near Rainbow Vegetarian Café.', 'Blue Spice is a family-friendly pub.', 'Blue Spice is a pub in the city centre.', 'Blue Spice is located in the city centre.']\n",
      "['Blue Spice is a pub that is not family friendly.', 'Blue Spice is a family friendly pub.', 'Blue Spice is located in the city centre.', 'Blue Spice is located in the city centre.', 'Blue Spice is a restaurant that is not family friendly.', 'Blue Spice is located in the riverside area near Rainbow Vegetarian Café.', 'Blue Spice is a non family friendly restaurant in the city centre.', 'Blue Spice is located in the city centre.']\n",
      "['Blue Spice is a family-friendly restaurant.', 'Blue Spice is a family friendly restaurant.', 'The Lowns is a coffee shop near All Bar One.', 'The Lowns is located near the Crowne Plaza Hotel.', 'The Sorrento is a coffee shop with a price of 5 stars.', 'The pub is located near All Bar One.', 'The pub is located near Crowne Plaza Hotel.', 'The Sorrento is a pub that serves fast food.']\n",
      "['Cocum is a coffee shop near Burger King.', 'Cocum is a coffee shop near Café Sicilia.', 'Cocum is a coffee shop near Café Sicilia.', 'Cocum is a coffee shop near Express by Holiday Inn.', 'Cocum is located near The Rice Boat.', 'Cocum is located near The Sorrento.', 'Cocum is a pub near Burger King.', 'Cocum is a pub near Café Sicilia.']\n",
      "['Cocum is a pub near Café Sicilia.', 'Cocum is a pub near Express by Holiday Inn.', 'Cocum is a pub near The Rice Boat.', 'Cocum is a pub near The Sorrento.', 'Cotto is located near The Bakers.', 'Cotto is a pub near The Bakers.', 'The Bakers is a coffee shop that serves fast food.', 'The Rice Boat is a coffee shop that serves food.']\n",
      "['The Giraffe is located near Rainbow Vegetarian Café.', 'The Giraffe is located in the city centre.', 'The Giraffe is located in the city centre near Rainbow Vegetarian Café.', 'The Giraffe is located in the riverside area near Rainbow Vegetarian Café.', 'The Giraffe is located near Rainbow Vegetarian Café.', 'The Giraffe is located in the riverside area near Raja Indian Cuisine.', 'The Giraffe is located in the city centre.', 'The Giraffe is located in the city centre near Raja Indian Cuisine.']\n",
      "['The Giraffe is located in the riverside area near Raja Indian Cuisine.', 'The Giraffe is located near Ranch Indian Cuisine.', 'The Bakers is a pub that serves fast food.', 'The Rice Boat is a pub that serves fast food.', 'The Giraffe is located near Rainbow Vegetarian Café.', 'The Giraffe is located in the city centre.', 'The Giraffe is located in the city centre near Rainbow Vegetarian Café.', 'The Giraffe is located in the riverside area near Rainbow Vegetarian Café.']\n",
      "['The Giraffe is located in the riverside area near Rainbow Vegetarian Café.', 'The Giraffe is located in the riverside area near Raja Indian Cuisine.', 'The Giraffe is located in the city centre.', 'The Giraffe is located in the city centre near Raja Indian Cuisine.', 'The Giraffe is located in the riverside area near Raja Indian Cuisine.', 'The Giraffe is located near Ranch Indian Cuisine.', 'Green Man is a coffee shop near All Bar One.', 'Green Man is a coffee shop near All Bar One.']\n",
      "['Green Man is a pub near All Bar One.', 'Green Man is a pub near All Bar One.', 'The Green Man is a family friendly pub.', 'The Green Man is a family friendly pub.', 'The Green Man is not family friendly.', 'The Green Man is located in the city centre.', 'The Green Man is not family friendly.', 'The Green Man is a family friendly pub.']\n",
      "['The Green Man is a family friendly restaurant.', 'The Green Man is a family friendly restaurant.', 'The Green Man is not family friendly.', 'The Green Man is located in the city centre.', 'The Green Man is not family friendly.', 'The Green Man is a family friendly restaurant.', 'Loch Fyne is a coffee shop located in the riverside.', 'Loch Fyne is a pub located in the riverside.']\n",
      "['The Strada is located in the city centre.', 'The Strada is located near All Bar One.', 'The Strada is located near Rainbow Vegetarian Café.', 'The Strada is located near Express by Holiday Inn.', 'The Strada is located in the city centre.', 'The Strada pub is located near All Bar One.', 'The Strada is located near Rainbow Vegetarian Café.', 'The Strada pub is near Express by Holiday Inn.']\n",
      "['The Cricketers is a coffee shop near Avalon.', 'The Cricketers is a family friendly coffee shop near Avalon.', 'The Cricketers is a coffee shop near Crowne Plaza Hotel.', 'The Cricketers is not family friendly.', 'The Cricketers is a family friendly coffee shop near Crowne Plaza Hotel.', 'The Cricketers is not family friendly.', 'The Cricketers is not family friendly.', 'The Cricketers is a family friendly coffee shop near Café Sicilia.']\n",
      "['The Cricketers is a coffee shop near Café Sicilia.', 'The Cricketers is a coffee shop near Express by Holiday Inn.', 'The Cricketers is not family friendly.', 'The Cricketers is a low customer rating.', 'The Cricketers is a coffee shop near Ranch.', 'The Cricketers is a family friendly restaurant.', 'The Cricketers is a family friendly restaurant.', 'The Cricketers is a family friendly restaurant near Crowne Plaza Hotel.']\n",
      "['The Cricketers is not family friendly.', 'The Cricketers is a family friendly restaurant near Crowne Plaza Hotel.', 'The Cricketers is not family friendly.', 'The Cricketers is not family friendly.', 'The Cricketers is a family friendly restaurant near Café Sicilia.', 'The Cricketers is a family friendly restaurant near Café Sicilia.', 'The Cricketers is a family friendly restaurant near Express by Holiday Inn.', 'The Cricketers is not family friendly.']\n",
      "['The Cricketers is a restaurant that is not family friendly.', 'The Cricketers is a family friendly restaurant.', 'The Cricketers is a restaurant that is not family friendly.', 'The Cricketers is a family friendly restaurant in the city centre.', 'The Cricketers is a restaurant that is not family friendly.', 'The Cricketers is a family friendly restaurant.', 'The Cricketers is a restaurant that is not family friendly.', 'The Cricketers is a family friendly restaurant in the city centre.']\n",
      "['The Cricketers is a restaurant that is not family friendly.', 'The Cricketers is a family friendly restaurant located in the riverside area near All Bar One.', 'The Cricketers is a restaurant that serves Chinese food.', 'The Cricketers is a family friendly restaurant in the city centre.', 'The Cricketers is a restaurant that serves Chinese food.', 'The Cricketers is a family friendly restaurant located in the riverside area.', 'The Cricketers is a restaurant that serves Chinese food in the city centre.', 'The Cricketers is a family friendly restaurant in the city centre.']\n",
      "['The Cricketers is a restaurant that serves Chinese food.', 'The Cricketers is a family friendly restaurant located in the riverside area near All Bar One.', 'The Cricketers is a restaurant that serves Chinese food in the city centre.', 'The Cricketers is a family friendly restaurant in the city centre.', 'The Cricketers is a restaurant that serves Chinese food.', 'The Cricketers is a family friendly restaurant located in the riverside area near All Bar One.', 'The Cricketers is a Chinese restaurant in the city centre. It has a customer rating of 1 out of 5.', 'The Cricketers is a family friendly restaurant in the city centre.']\n",
      "['The Cricketers is a Chinese restaurant in the moderate price range.', 'The Cricketers is a family friendly restaurant.', 'The Cricketers is a Chinese restaurant in the city centre.', 'The Cricketers is a family friendly restaurant in the city centre.', 'The Cricketers is a Chinese restaurant in the moderate price range.', 'The Cricketers is a family friendly restaurant.', 'The Cricketers is a restaurant that serves Chinese food.', 'The Cricketers is a family friendly restaurant in the city centre.']\n",
      "['The Cricketers is a restaurant that serves Chinese food.', 'The Cricketers is a family friendly restaurant.', 'The Cricketers is a restaurant that is not family friendly.', 'The Cricketers is a family friendly restaurant in the city centre.', 'The Cricketers is a restaurant that serves Chinese food.', 'The Cricketers is a family friendly restaurant.', 'The Cricketers is a restaurant that is not family friendly.', 'The Cricketers is a family friendly restaurant in the city centre.']\n",
      "['The Cricketers is a restaurant that is not family friendly.', 'The Cricketers is a family friendly restaurant.', 'The Cricketers is a restaurant that is not family friendly.', 'The Cricketers is a family friendly restaurant in the city centre.', 'The Cricketers is a family friendly restaurant located in the riverside area.', 'The Cricketers is a family friendly restaurant located in the riverside area near Café Rouge.', 'The Cricketers is a restaurant that serves English food in the high price range.', 'The Cricketers is a family friendly restaurant in the city centre.']\n",
      "['The Cricketers is a family friendly restaurant located in the riverside area.', 'The Cricketers is a family friendly restaurant located in the riverside area.', 'The Cricketers is a restaurant that is not family friendly.', 'The Cricketers is a family friendly restaurant in the city centre.', 'The Cricketers is a family friendly restaurant located in the riverside area.', 'The Cricketers is a restaurant that serves English food in the city centre.', 'The Cricketers is a family friendly restaurant in the city centre.', 'The Cricketers is a family friendly restaurant.']\n",
      "['The Cricketers is a family friendly restaurant.', 'The Mill is a pub that serves English food.', 'The Mill is a pub that is not family friendly.', 'The Mill is a pub that serves English food in the city centre.', 'The Mill is a pub that is not family friendly.', 'The Mill is a pub that serves English food.', 'The Mill is a pub that is not family friendly.', 'The Mill is a pub that serves English food in the moderate price range.']\n",
      "['The Mill is a pub that is not family friendly.', 'The Mill is a family friendly pub.', 'The Mill is a pub that serves English food.', 'The Mill is a family friendly pub in the riverside area.', 'The Mill is a family friendly pub in the city centre.', 'The Mill is a family friendly pub in the city centre.', 'The Mill is a family friendly pub in the riverside area.', 'The Mill is a family friendly pub in the riverside area.']\n",
      "['The Mill is a family friendly pub in the city centre.', 'The Mill is a family friendly pub in the city centre.', 'The Mill is a family friendly pub in the riverside area.', 'The Mill is a family friendly pub in the riverside area.', 'The Mill is a pub that is not family friendly.', 'The Mill is a family friendly pub in the city centre.', 'The Mill is a family friendly pub in the riverside area.', 'The Mill is a family friendly pub in the riverside area.']\n",
      "['The Mill is a pub in the city centre. It is not family friendly.', 'The Mill is a family friendly pub in the city centre.', 'The Mill is a family friendly pub in the riverside area.', 'The Mill is a family friendly pub in the riverside area.', 'The Mill is a pub in the city centre. It is not family friendly.', 'The Mill is a family friendly pub in the city centre.', 'The Mill is a pub that is not family friendly.', 'The Mill is a family friendly pub in the riverside area.']\n",
      "['The Mill is a pub that is not family friendly.', 'The Mill is a family friendly pub in the city centre.', 'The Mill is a family friendly pub in the riverside area.', 'The Mill is a family friendly pub in the riverside area.', 'The Mill is a pub that is not family friendly.', 'The Mill is a family friendly pub in the city centre.', 'The Mill is a family friendly pub in the riverside area.', 'The Mill is a family friendly pub in the riverside area.']\n",
      "['The Mill is a family friendly pub.', 'The Mill is a pub in the city centre. It has a high customer rating.', 'The Mill is a family friendly pub in the city centre.', 'The Mill is a pub that is not family friendly.', 'The Mill is a family friendly pub.', 'The Mill is a family friendly pub in the riverside area.', 'The Mill is a family friendly restaurant.', 'The Mill is a family friendly restaurant located in the riverside area.']\n",
      "['The Mill is a restaurant that serves English food in the city centre.', 'The Mill is a family friendly restaurant in the city centre.', 'The Mill is a family-friendly restaurant.', 'The Mill is a family friendly restaurant.', 'The Mill is a low customer rating.', 'The Mill is a family friendly restaurant in the city centre.', 'The Mill is a family friendly restaurant.', 'The Mill is a family friendly restaurant.']\n",
      "['The Mill is a family friendly restaurant in the city centre.', 'The Mill is a family friendly restaurant in the city centre.', 'The Mill is a family friendly restaurant.', 'The Mill is a family friendly restaurant.', 'The Mill is a family friendly restaurant in the city centre.', 'The Mill is a family friendly restaurant in the city centre.', 'The Mill is a family friendly restaurant.', 'The Mill is a family friendly restaurant.']\n",
      "['The Mill is a family friendly restaurant in the city centre.', 'The Mill is a family friendly restaurant in the city centre.', 'The Mill is a family friendly restaurant.', 'The Mill is a family friendly restaurant.', 'The Mill is a family friendly restaurant.', 'The Mill is a restaurant that serves English food.', 'The Mill is a family friendly restaurant in the city centre.', 'The Mill is a family friendly restaurant.']\n",
      "['The Mill is a family friendly restaurant.', 'The Mill is a family friendly restaurant.', 'The Mill is a family friendly restaurant.', 'The Phoenix is a family friendly pub in the riverside area.', 'The Phoenix is a pub in the city centre.', 'The Phoenix is a family friendly pub in the city centre.', 'The Phoenix is a family-friendly pub in the riverside area.', 'The Phoenix is a family friendly pub in the riverside area.']\n",
      "['The Phoenix is a pub in the city centre.', 'The Phoenix is a family friendly pub in the city centre.', 'The Phoenix is a family-friendly pub in the riverside area.', 'The Phoenix is a family friendly pub.', 'The Phoenix is a pub in the city centre.', 'The Phoenix is a family friendly pub in the city centre.', 'The Phoenix is a family-friendly pub in the riverside area.', 'The Phoenix is a family friendly pub in the riverside area.']\n",
      "['The Phoenix is a family friendly pub in the riverside area.', 'The Phoenix is a family friendly pub.', 'The Phoenix is a pub that is not family friendly.', 'The Phoenix is a family friendly pub in the city centre.', 'The Phoenix is a family friendly pub in the riverside area.', 'The Phoenix is a family friendly pub.', 'The Phoenix is a family friendly pub in the riverside area.', 'The Phoenix is a French pub in the city centre.']\n",
      "['The Phoenix is a family friendly pub in the city centre.', 'The Phoenix is a French pub in the riverside area.', 'The Phoenix is a family friendly pub in the riverside area.', 'The Phoenix is a family friendly pub in the riverside area.', 'The Phoenix is a French pub in the city centre.', 'The Phoenix is a family friendly pub in the city centre.', 'The Phoenix is a French pub located in the riverside area.', 'The Phoenix is a family friendly pub in the riverside area.']\n",
      "['The Phoenix is a French pub in the city centre.', 'The Phoenix is a family friendly pub in the city centre.', 'The Phoenix is a French pub located in the riverside area.', 'The Phoenix is a family friendly pub located in the riverside area.', 'The Phoenix is a French pub in the city centre.', 'The Phoenix is a family friendly pub in the city centre.', 'The Phoenix is a family-friendly pub located in the riverside area.', 'The Phoenix is a family friendly pub in the riverside area.']\n",
      "['The Phoenix is a family-friendly pub in the city centre.', 'The Phoenix is a family friendly pub in the city centre.', 'The Phoenix is a family-friendly pub in the riverside area.', 'The Phoenix is a family friendly pub in the riverside area.', 'The Phoenix is a French pub in the city centre.', 'The Phoenix is a family friendly pub in the city centre.', 'The Phoenix is a French pub in the riverside area.', 'The Phoenix is a family friendly pub.']\n",
      "['The Phoenix is a French pub in the city centre.', 'The Phoenix is a family friendly pub in the city centre.', 'The Phoenix is a French pub in the riverside area.', 'The Phoenix is a family friendly pub in the riverside area.', 'The Phoenix is a family-friendly pub.', 'The Phoenix is a French pub in the city centre.', 'The Phoenix is a French pub in the city centre.', 'The Phoenix is a French pub in the riverside area.']\n",
      "['The Phoenix is a family friendly pub in the riverside area.', 'The Phoenix is a family friendly pub in the riverside area.', 'The Phoenix is a French pub in the city centre.', 'The Phoenix is a family friendly pub in the city centre.', 'The Phoenix is a family-friendly pub in the riverside area.', 'The Phoenix is a family friendly pub in the riverside area.', 'The Phoenix is a family friendly restaurant.', 'The Phoenix is a restaurant that is not family friendly.']\n",
      "['The Phoenix is a family friendly restaurant in the city centre.', 'The Phoenix is a family friendly restaurant.', 'The Phoenix is a family friendly restaurant.', 'The Phoenix is a family-friendly restaurant in the city centre.', 'The Phoenix is a family friendly restaurant in the city centre.', 'The Phoenix is a family friendly restaurant.', 'The Phoenix is a family friendly restaurant.', 'The Phoenix is a family friendly restaurant in the city centre.']\n",
      "['The Phoenix is a family friendly restaurant in the city centre.', 'The Phoenix is a family friendly restaurant.', 'The Phoenix is a family friendly restaurant.', 'The Phoenix is a family friendly restaurant.', 'The Phoenix is a family friendly restaurant located in the riverside area.', 'The Phoenix is a family friendly restaurant located in the riverside area.', 'The Phoenix is a family friendly restaurant.', 'The Phoenix is a restaurant that is not family friendly.']\n",
      "['The Phoenix is a family friendly restaurant in the city centre.', 'The Phoenix is a restaurant that is not family friendly.', 'The Phoenix is a family friendly restaurant located in the riverside area.', 'The Phoenix is a family friendly restaurant located near Express by Holiday Inn.', 'The Phoenix is a restaurant that is not family friendly.', 'The Phoenix is a restaurant that is not family friendly.', 'The Phoenix is a family friendly restaurant in the city centre.', 'The Phoenix is a family friendly restaurant in the riverside area.']\n",
      "['The Phoenix is a family friendly restaurant located in the riverside area.', 'The Plough is a Chinese pub in the riverside area near Raja Indian Cuisine.', 'The Plough is a Chinese pub in the city centre.', 'The Plough is located in the city centre near Raja Indian Cuisine.', 'The Plough is a Chinese pub in the riverside area.', 'The Plough is a family friendly pub in the riverside area.', 'The Plough is a Chinese pub in the city centre.', 'The Plough is a Chinese pub in the riverside area near Raja Indian Cuisine.']\n",
      "['The Plough is a family friendly restaurant.', 'The Plough is a restaurant that serves Chinese food in the city centre.', 'The Plough is located in the city centre near Raja Indian Cuisine.', 'The Plough is a restaurant that serves Chinese food.', 'The Plough is a family friendly restaurant.', 'The Plough is a Chinese restaurant in the city centre.', 'The Plough is a family friendly restaurant.', 'The Punter is located in the city centre near Raja Indian Cuisine.']\n",
      "['The Punter is a Chinese pub in the riverside area.', 'The Punter is a family-friendly pub.', 'The Punter is a Chinese pub in the city centre.', 'The Punter is a Chinese pub in the city centre.', 'The Punter is a Chinese pub in the riverside area.', 'The Punter is a family friendly pub in the riverside area.', 'The Punter is a family-friendly pub.', 'The Punter is a family friendly pub in the riverside area.']\n",
      "['The Punter is a pub in the city centre.', 'The Punter is located in the city centre near Raja Indian Cuisine.', 'The Punter is a pub that is not family friendly.', 'The Punter is a family friendly pub in the riverside area.', 'The Punter is a family friendly pub in the riverside area.', 'The Punter is a pub in the city centre. It is not family friendly.', 'The Punter is located in the city centre near Raja Indian Cuisine.', 'The Punter is a restaurant that serves Chinese food.']\n",
      "['The Punter is a family friendly restaurant located in the riverside area.', 'The Punter is a Chinese restaurant in the city centre.', 'The Punter is a family friendly restaurant in the city centre.', 'The Punter is a Chinese restaurant in the moderate price range.', 'The Punter is a family friendly restaurant in the riverside area.', 'The Punter is a family friendly restaurant located in the riverside area.', 'The Punter is a family friendly restaurant.', 'The Punter is a restaurant that serves English food in the city centre.']\n",
      "['The Punter is located in the city centre near Raja Indian Cuisine.', 'The Punter is a restaurant that serves English food.', 'The Punter is a family friendly restaurant located in the riverside area.', 'The Punter is a family friendly restaurant.', 'The Punter is a family friendly restaurant in the city centre.', 'The Punter is a family friendly restaurant located in the riverside area.', 'The Punter is a family friendly restaurant located in the riverside area near Express by Holiday Inn.', 'The Punter is a restaurant that is not family friendly.']\n",
      "['The Punter is a family friendly restaurant in the city centre.', 'The Punter is a family friendly restaurant located in the riverside area.', 'The Punter is a family friendly restaurant located in the riverside area.', 'The Punter is a restaurant that is not family friendly.', 'The Punter is a family friendly restaurant in the city centre.', 'The Punter is a family friendly restaurant located in the riverside area.', 'The Punter is a family friendly restaurant located in the riverside area.', 'The Punter is a low customer rating.']\n",
      "['The Punter is a family friendly restaurant in the city centre.', 'The Punter is a family friendly restaurant located in the riverside area.', 'The Punter is a family friendly restaurant located near Express by Holiday Inn.', 'The Punter is a family friendly restaurant in the city centre.', 'The Punter is a family friendly restaurant in the city centre.', 'The Punter is a family friendly restaurant located in the riverside area.', 'The Punter is a family friendly restaurant located in the riverside area.', 'The Punter is a family friendly restaurant in the city centre.']\n",
      "['The Punter is a family friendly restaurant in the city centre.', 'The Punter is a family friendly restaurant in the riverside area.', 'The Punter is a family friendly restaurant located in the riverside area.', 'The Punter is a restaurant that is not family friendly.', 'The Punter is a family friendly restaurant in the city centre.', 'The Punter is a family friendly restaurant located in the riverside area.', 'The Punter is a family friendly restaurant located in the riverside area near Express by Holiday Inn.', 'The Punter is a restaurant that is not family friendly.']\n",
      "['The Punter is a restaurant that is not family friendly.', 'The Punter is a family friendly restaurant in the city centre.', 'The Punter is a restaurant that is not family friendly.', 'The Punter is a family friendly restaurant located in the riverside area near Rainbow Vegetarian Café.', 'The Punter is a restaurant that is not family friendly.', 'The Punter is a family friendly restaurant in the city centre.', 'The Punter is a restaurant that is not family friendly.', 'The Punter is a family friendly restaurant located in the riverside area near Rainbow Vegetarian Café.']\n",
      "['The Punter is a restaurant that is not family friendly.', 'The Punter is a family friendly restaurant in the city centre.', 'The Punter is a restaurant that is not family friendly.', 'The Punter is a family friendly restaurant located in the riverside area near Rainbow Vegetarian Café.', 'The Punter is a restaurant that is not family friendly.', 'The Punter is a family friendly restaurant in the city centre.', 'The Punter is a restaurant that is not family friendly.', 'The Punter is a family friendly restaurant located near Express by Holiday Inn.']\n",
      "['The Vaults is a family friendly pub located in the riverside area.', 'The Vaults is a French pub in the city centre.', 'The Vaults is a French pub in the city centre.', 'The Vaults is a French pub located in the riverside.', 'The Vaults is a family friendly pub located in the riverside.', 'The Vaults is a French pub in the city centre.', 'The Vaults is a family friendly pub in the city centre.', 'The Vaults is a French pub in the riverside area.']\n",
      "['The Vaults is a family friendly pub in the riverside area.', 'The Vaults is a French pub in the city centre.', 'The Vaults is a French pub in the city centre.', 'The Vaults is a French pub in the riverside area.', 'The Vaults is a family friendly pub located in the riverside.', 'The Vaults is a family friendly pub in the riverside area.', 'The Vaults is a pub in the city centre.', 'The Vaults is a family friendly pub in the city centre.']\n",
      "['The Vaults is a family friendly pub.', 'The Vaults is a pub that is not family friendly.', 'The Vaults is a family friendly pub in the city centre.', 'The Vaults is a pub that is not family friendly.', 'The Vaults is a family friendly pub located near Rainbow Vegetarian Café.', 'The Vaults is a pub that is not family friendly.', 'The Vaults is a pub that is not family friendly.', 'The Vaults is a pub that is not family friendly.']\n",
      "['The Vaults is a family friendly pub located near Rainbow Vegetarian Café.', 'The Vaults is a pub that is not family friendly.', 'The Vaults is a family friendly pub in the city centre.', 'The Vaults is a family friendly pub located in the riverside area.', 'The Vaults is a family friendly pub located in the riverside area.', 'The Vaults is a pub that is not family friendly.', 'The Vaults is a family friendly pub in the city centre.', 'The Vaults is a family friendly pub located in the riverside area.']\n",
      "['The Vaults is a family friendly pub located in the riverside area.', 'The Vaults is a pub that is not family friendly.', 'The Vaults is a family friendly pub in the city centre.', 'The Vaults is a pub that is not family friendly.', 'The Vaults is a family friendly pub located in the riverside area near Rainbow Vegetarian Café.', 'The Vaults is a Japanese pub in the city centre.', 'The Vaults is a family friendly pub in the city centre.', 'The Vaults is a Japanese pub in the riverside area.']\n",
      "['The Vaults is a family friendly pub in the riverside area.', 'The Vaults is a Japanese pub in the city centre.', 'The Vaults is a family friendly pub in the city centre.', 'The Vaults is a Japanese pub located in the riverside area.', 'The Vaults is a family friendly pub in the riverside area.', 'The Vaults is a Japanese pub in the city centre.', 'The Vaults is a family friendly pub in the city centre.', 'The Vaults is a Japanese pub located in the riverside area.']\n",
      "['The Vaults is a family friendly pub located in the riverside area.', 'The Vaults is a Japanese pub in the city centre.', 'The Vaults is a family friendly pub in the city centre.', 'The Vaults is a Japanese pub located in the riverside area.', 'The Vaults is a family friendly pub located in the riverside area.', 'The Vaults is a Japanese pub in the city centre.', 'The Vaults is a family friendly pub in the city centre.', 'The Vaults is a Japanese pub in the city centre.']\n",
      "['The Vaults is a family friendly pub in the city centre.', 'The Vaults is a Japanese pub in the riverside area.', 'The Vaults is a family friendly pub in the riverside area.', 'The Vaults is a Japanese pub in the city centre.', 'The Vaults is a family friendly pub in the city centre.', 'The Vaults is a family friendly pub located in the riverside area.', 'The Vaults is a Japanese pub in the riverside area.', 'The Vaults is a family friendly pub in the riverside area.']\n",
      "['The Vaults is a family friendly restaurant located in the riverside area.', 'The Vaults is a restaurant that serves French food.', 'The Vaults is a family friendly restaurant in the city centre.', 'The Vaults is a restaurant that serves French food.', 'The Vaults is a family friendly restaurant located in the riverside area.', 'The Vaults is a restaurant that serves French food in the city centre.', 'The Vaults is a family friendly restaurant in the city centre.', 'The Vaults is a family friendly restaurant.']\n",
      "['The Vaults is a family friendly restaurant.', 'The Vaults is a restaurant that serves French food.', 'The Vaults is a family friendly restaurant in the city centre.', 'The Vaults is a restaurant that serves French food.', 'The Vaults is a family friendly restaurant.', 'The Vaults is a family friendly restaurant.', 'The Vaults is a restaurant that is not family friendly.', 'The Vaults is a family friendly restaurant in the city centre.']\n",
      "['The Vaults is a family friendly restaurant.', 'The Waterman is a pub that is family friendly.', 'The Waterman is a pub that is not family friendly.', 'The Waterman is a family friendly pub located in the riverside area.', 'The Waterman is a pub that is not family friendly.', 'The Waterman is a pub that is not kid friendly.', 'The Waterman is a pub that is not family friendly.', 'The Waterman is a family friendly pub located in the riverside area.']\n",
      "['The Waterman is a pub in the city centre.', 'The Waterman is a family friendly pub in the city centre.', 'The Waterman is a pub that is not family friendly.', 'The Waterman is a family friendly pub in the riverside area.', 'The Waterman is a family friendly pub located in the riverside area.', 'The Waterman is a family friendly pub located in the riverside area.', 'The Waterman is a pub that is not family friendly.', 'The Waterman is a pub that is family friendly.']\n",
      "['The Waterman is a pub that is not family friendly.', 'The Waterman is a family friendly pub located in the riverside area.', 'The Waterman is a pub that is not family friendly.', 'The Waterman is a pub that is not kid friendly.', 'The Waterman is a pub that is not family friendly.', 'The Waterman is a family friendly pub located in the riverside area.', 'The Waterman is a family friendly restaurant in the city centre.', 'The Waterman is a family friendly restaurant located in the riverside area.']\n",
      "['The Waterman is a family friendly restaurant located in the riverside area.', 'The Waterman is a restaurant that is not family friendly.', 'The Waterman is a family friendly restaurant located in the city centre.', 'The Waterman is a family friendly restaurant located in the riverside area.', 'The Waterman is a family friendly restaurant located in the riverside area.', 'The Waterman is a family friendly restaurant in the city centre.', 'The Waterman is a family friendly restaurant in the city centre.', 'The Waterman is a family friendly restaurant in the riverside area.']\n",
      "['The Waterman is a family friendly restaurant located in the riverside area.', 'The Waterman is a family friendly restaurant located in the riverside area.', 'The Waterman is a family friendly restaurant located in the riverside area.', 'The Waterman is a restaurant that is not family friendly.', 'The Waterman is a family friendly restaurant in the city centre.', 'The Waterman is a restaurant that is not family friendly.', 'The Waterman is a family friendly restaurant located in the riverside area.', 'The Waterman is a non family friendly restaurant in the city centre.']\n",
      "['The Waterman is a family friendly restaurant located in the city centre.', 'The Waterman is a non family friendly restaurant.', 'The Waterman is a family friendly restaurant located in the riverside area.', 'The Wrestlers is a pub that is not family friendly.', 'The Wrestlers is a family friendly pub located in the riverside.', 'The Wrestlers is a pub in the city centre.', 'The Wrestlers is a family friendly pub in the city centre.', 'The Wrestlers is a family friendly pub in the riverside area.']\n",
      "['The Wrestlers is a family friendly pub in the riverside area.', 'The Wrestlers is a family friendly pub located in the riverside.', 'The Wrestlers is a family friendly pub in the riverside area.', 'The Wrestlers is a family friendly pub in the riverside area.', 'The Wrestlers is a Japanese pub in the city centre.', 'The Wrestlers is a family friendly pub in the city centre.', 'The Wrestlers is a family friendly pub in the riverside area.', 'The Wrestlers is a family friendly pub located in the riverside area.']\n",
      "['The Wrestlers is a Japanese pub in the city centre.', 'The Wrestlers is a family friendly pub in the city centre.', 'The Wrestlers is a family friendly pub in the riverside area.', 'The Wrestlers is a family friendly pub in the riverside area.', 'The Wrestlers is a family friendly pub in the city centre.', 'The Wrestlers is a family friendly pub in the riverside area.', 'The Wrestlers is a family friendly pub in the riverside area.', 'The Wrestlers is a Japanese pub in the city centre.']\n",
      "['The Wrestlers is a family friendly pub in the city centre.', 'The Wrestlers is a family friendly pub in the riverside area.', 'The Wrestlers is a family friendly pub located in the riverside area.', 'The Wrestlers is a Japanese pub in the city centre.', 'The Wrestlers is a family friendly pub in the city centre.', 'The Wrestlers is a family friendly pub in the riverside area.', 'The Wrestlers is a family friendly pub.', 'The Wrestlers is a pub in the city centre. It is not family friendly.']\n",
      "['The Wrestlers is a family friendly pub in the city centre.', 'The Wrestlers is a family friendly pub in the riverside area.', 'The Wrestlers is a family friendly pub.', 'The Wrestlers is a family friendly pub.', 'The Wrestlers is a family friendly restaurant.', 'The Wrestlers is a family friendly restaurant located in the riverside area.', 'The Wrestlers is a family friendly restaurant in the city centre.', 'The Wrestlers is a family friendly restaurant in the city centre.']\n",
      "['The Wrestlers is a family friendly restaurant.', 'The Wrestlers is a family friendly restaurant.', 'The Wrestlers is a family friendly restaurant.', 'The Wrestlers is a family friendly restaurant.', 'The Wrestlers is a family friendly restaurant.', 'The Wrestlers is a family friendly restaurant in the city centre.', 'The Wrestlers is a family friendly restaurant in the city centre.', 'The Wrestlers is a family friendly restaurant.']\n",
      "['The Wrestlers is a family friendly restaurant.', 'The Wrestlers is a family friendly restaurant in the city centre.', 'The Wrestlers is located in the city centre near Raja Indian Cuisine.', 'The Wrestlers is a family friendly restaurant.', 'The Wrestlers is a family friendly restaurant.', 'The Wrestlers is a family friendly restaurant in the city centre.', 'The Wrestlers is a family friendly restaurant in the city centre.', 'The Wrestlers is a family friendly restaurant.']\n",
      "['The Wrestlers is a family friendly restaurant.', 'The Wrestlers is a family friendly restaurant.', 'Wildwood is a coffee shop located in the riverside.', 'Wildwood is a pub located in the riverside.', 'Wildwood is a family friendly pub near Ranch Indian Cuisine.', 'Wildwood is a pub in the city centre.', 'Wildwood is a pub in the city centre.', 'Wildwood is a pub that is not family friendly.']\n",
      "['Wildwood is a family-friendly pub.', 'Wildwood is a pub in the city centre.', 'Wildwood is a pub that is family friendly.', 'Wildwood is a pub that is not family friendly.', 'Wildwood is a family friendly pub near Raja Indian Cuisine.', 'Wildwood is a family friendly restaurant.', 'Wildwood is a non family friendly restaurant in the city centre.', 'Wildwood is a family friendly restaurant in the city centre.']\n",
      "['Wildwood is a non family friendly restaurant.', 'Wildwood is a family friendly restaurant.', 'Wildwood is a non family friendly restaurant in the city centre.', 'Wildwood is a family friendly restaurant in the city centre.', 'Wildwood is a non family friendly restaurant.', 'Wildwood is a family friendly restaurant.', 'Zizzi is a coffee shop located in the riverside.', 'Zizzi is a coffee shop near Burger King.']\n"
     ]
    }
   ],
   "source": [
    "model_predictions = make_predictions(model=model_t5,inputs_test=inputs_test_e2e,tokenizer=tokenizer_t5,challenge_name='e2e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', \"X.,s thea: and to of fille int- is de for’i that youd I withn on'o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (a/amuse-01:ARG0(t/that):degree(s/so)))\", \"X.,s thea: and to of fille int- is de for’i that youd I withn on'o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (a/and:modeexpressive:op2(p2/prince:mod(l2/little):mod(d/dear))))\", '', '', '', '', '']\n",
      "['', '', 'a a a a a a(l/little)):ARG1(g/globe:consist-of(g2/glass):poss(s2/she):op1-of(u/under:location-of(f2/flower:mod(l2/little):possp))))):time(r/rate-entity-91:ARG4(n/', '', '', '', '', '']\n",
      "[\"X.,s thea: and to of fille int- is de for’i that youd I withn on'o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (a/and:op2(l/laugh-01:ARG0(h/he):mod(a2/again)))))\", '', '', '', '', '', \"X.,s thea: and to of fille int- is de for’i that youd I withn on'o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (a/and:op2(s/sit-down-02:ARG1(h/he):ARG1-of(c/cause-01:ARG0(f/fear-01:ARG0h))))\", 'X.,s thea: and to of fille int- is de for’i that youd I withn on’o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (a/and:op2(s/sweet-05:ARG1(l/laugh-01:ARG0(s2/star:mod(a2/all))))))))))))))))))']\n",
      "['', '', '', '', '', '', '', 'X.,s thea:']\n",
      "['X.,s thea:', '', \"X.,s thea: and to of fille int- is de for’i that youd I withn on'o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (c/comfort-01:ARG1(s/sorrow-01:ARG0(i/i)):time(n/now):degree(l/little)))\", '', '', '', '', '']\n",
      "['', '', '', \"X.,s thea: and to of fille int- is de for’i that youd I withn on'o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (c/contrast-01:ARG2(l/laugh-01:ARG0(h/he):manner(l2/light-06)))))\", '', '', '', '']\n",
      "['', '', 'X.,s thea:', \"X.,s thea: and to of fille int- is de for’i that youd I withn on'o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (c/cry-out-03:ARG0(h/he):polarity-)\", '', \"X.,s thea: and to of fille int- is de for’i that youd I withn on'o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (d/discourage-01:ARG1(h/he):degree(l/little)))\", '', \"X.,s thea: and to of fille int- is de for’i that youd I withn on'o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (f/fear-01:ARG0(h/he):mod(c/certain)))\"]\n",
      "['', '', '', '', \"X.,s thea: and to of fille int- is de for’i that youd I withn on'o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (h/happy-01:ARG1(i/i):time(t/then)))\", '', '', '']\n",
      "['', '', '', '', '', 'X.,s thea:  X.,s thea:  X.,s thea:  X.,s thea:  X.,s thea:  X.,s thea:  X.,s thea:  X.,s thea:  X.,s thea:  X.,s thea:  X.,s  X.,', '', \"X.,s thea: and to of fille int- is de for’i that youd I withn on'o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (k/know-01:ARG0(i/i)))\"]\n",
      "['', \"X.,s thea: and to of fille int- is de for’i that youd I withn on'o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (l/laugh-01:ARG0(h/he):mod(a/again)))\", '', '', '', \"X.,s thea: and to of fille int- is de for’i that youd I withn on'o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (l/look-01:ARG0(i/i:mod(t/too)):ARG1(s/star)))\", '', '']\n",
      "['', '', '', '', \"X.,s thea: and to of fille int- is de for’i that youd I withn on'o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (m/man:mod(l/little)))\", '', '', 'X.,s thea:']\n",
      "['X.,s thea:', '', '', '', '', '', '', '']\n",
      "['', '', '', '', '', \"X.,s thea: and to of fille int- is de for’i that youd I withn on'o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (p/present-01:ARG0(i/i):ARG1(t/that)))\", '', '']\n",
      "['', '', '', '', '', 'X.,s thea:  X.,s thea:', '', '']\n",
      "['X.,s thea:', '', '', '', \"X.,s thea: and to of fille int- is de for’i that youd I withn on'o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (s/say-01:ARG0(i/i)))\", \"X.,s thea: and to of fille int- is de for’i that youd I withn on'o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (s/say-01:ARG0(i/i):ARG1(f/fear-01:ARG0h):ARG2(h/he)))\", '', 'X.,s thea:  X.,s thea:  X.,s thea:  X.,s thea:  X.,s thea:  X.,s thea:']\n",
      "['', '', '', '', '', '', '', 'X.,s thea:  X.,s thea:']\n",
      "['', '', '', 'X.,s thea:  X.,s thea:  X.,s thea:  X.,s thea:  X.,s thea:  X.,s thea:  X.,s thea:  X.,s thea:  X.,s thea:  X.,s thea:', '', 'X.,s thea:', '', '']\n",
      "['', 'X.,s thea: and to of fille int- is de for’i that youd I withn on’o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (t/that:mod(a/all):time(n/now)))', 'X.,s thea:', '', \"X.,s thea: and to of fille int- is de for’i that youd I withn on'o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (t3/trick-01:ARG0(i/i):ARG1(y/you):mod(s2/shabby:degree(v2/very)))))\", '', \"X.,s thea: and to of fille int- is de for’i that youd I withn on'o are iten be The as yourl ( or have at from an was thiser translated from Graph to Text: (w/wait-01:ARG1(i/i):ARG1-of(l/long-03)))\", '']\n"
     ]
    }
   ],
   "source": [
    "model_predictions = make_predictions(model=model_t5,inputs_test=inputs_test_amr,tokenizer=tokenizer_t5,challenge_name='amr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_predictions = make_predictions(model=model_t5,inputs_test=inputs_test_web_nlg,tokenizer=tokenizer_t5,challenge_name='web_nlg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lb4uJ5Pq6KiP"
   },
   "source": [
    "## Save the Soft Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vLLVP5BW6Ma1"
   },
   "outputs": [],
   "source": [
    "model_t5.save_soft_prompt(challenge_name='e2e', epochs=str(epochs), model_size=f'{model_size}', number_tokens=number_prompt_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_t5.save_soft_prompt(challenge_name='web_nlg', epochs=str(epochs), model_size=f'{model_size}', number_tokens=number_prompt_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_t5.save_soft_prompt(challenge_name='amr', epochs=str(epochs), model_size=f'{model_size}', number_tokens=number_prompt_tokens)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "OIoYkDMph0qI",
    "qtPNBfoDh0qQ",
    "BNixl_L6qRAJ",
    "YA92MUkIh0qU",
    "j4u8a5oqh0qY",
    "uNBoD0Mth0qZ",
    "mQG9jyovcPZc"
   ],
   "machine_shape": "hm",
   "name": "prompt_tuning_t5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}