DATASETS:
  -
    KEY: amr_nlg
    DATASET_CONFIG: config/amr_nlg.yml

PRE_TRAINED_MODEL: t5-small
LOAD_MODEL: False
PROMPT_TUNING: False

SAMPLE: False
SAMPLE_SIZE:

NUMBER_PROMPT_TOKENS: 50
RANDOM_RANGE: 0.5
INIT_FROM_VOCAB: True

TRAIN: True
TRAIN_MODE: huggingface
EVALUATE: False

BATCH_SIZE: 8
EVAL_BATCH_SIZE: 8
EVAL_ACCUMULATION_STEPS: 1
EVAL_STEPS: 1000
GREATER_IS_BETTER: False
LEARNING_RATE: 0.001
LOAD_BEST_MODEL_AT_END: True
LOGGING_FIRST_STEP: False
LOGGING_STEPS: 10
METRIC_FOR_BEST_MODEL: loss
NUM_TRAIN_EPOCHS: 4
PREDICTION_LOSS_ONLY: True
REMOVE_UNUSED_COLUMNS: True
SAVE_STEPS: 1000
SAVE_TOTAL_LIMIT: 1
WANDB_RUN_NAME: amr_nlg_t5_small_ft

OUTPUT_DIR: amr_nlg_t5_small_ft
INPUT_DIR: runs/amr_nlg_t5_small_ft/models

SAVE_MODEL: True
SAVE_SOFT_PROMPTS: False