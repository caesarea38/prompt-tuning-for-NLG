DATASETS:
  -
    KEY: web_nlg
    DATASET_CONFIG: config/web_nlg.yml

PRE_TRAINED_MODEL: t5-small
PROMPT_TUNING: False
LOAD_MODEL: False
SAVE_MODEL: True

SAMPLE: False
SAMPLE_SIZE_TRAIN:
SAMPLE_SIZE_EVAL:

NUMBER_PROMPT_TOKENS:
RANDOM_RANGE:
INIT_FROM_VOCAB:

TRAIN: True
EVALUATE: True

BATCH_SIZE: 8
EVAL_BATCH_SIZE: 8
GREATER_IS_BETTER: False
LEARNING_RATE: 0.001
LOAD_BEST_MODEL_AT_END: True
LOGGING_FIRST_STEP: False
LOGGING_STEPS: 10
METRIC_FOR_BEST_MODEL: loss
NUM_TRAIN_EPOCHS: 4
OPTIMIZER: adafactor
LR_SCHEDULER: linear
PREDICTION_LOSS_ONLY: True
REMOVE_UNUSED_COLUMNS: True
REPORT_TO: wandb
SAVE_TOTAL_LIMIT: 3
WANDB_RUN_NAME: web_nlg_t5_small_fine_tuning

OUTPUT_DIR: web_nlg_t5_small_fine_tuning
INPUT_DIR:
WANDB_CONFIG: config/wandb.yml